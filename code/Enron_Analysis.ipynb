{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Dependencies\" data-toc-modified-id=\"Dependencies-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dependencies</a></span></li><li><span><a href=\"#Goal\" data-toc-modified-id=\"Goal-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Goal</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Tokenise-Email-Bodies\" data-toc-modified-id=\"Tokenise-Email-Bodies-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Tokenise Email Bodies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bigrams\" data-toc-modified-id=\"Bigrams-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Bigrams</a></span></li><li><span><a href=\"#Lemmatisation\" data-toc-modified-id=\"Lemmatisation-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Lemmatisation</a></span></li><li><span><a href=\"#Bigrams\" data-toc-modified-id=\"Bigrams-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Bigrams</a></span></li></ul></li><li><span><a href=\"#Construct-the-Corpus-and-LDA-model\" data-toc-modified-id=\"Construct-the-Corpus-and-LDA-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Construct the Corpus and LDA model</a></span><ul class=\"toc-item\"><li><span><a href=\"#construct-the-LDA-model\" data-toc-modified-id=\"construct-the-LDA-model-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>construct the LDA model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Perplexity-and-Coherence\" data-toc-modified-id=\"Perplexity-and-Coherence-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Perplexity and Coherence</a></span></li></ul></li></ul></li><li><span><a href=\"#Finding-Best-Number-of-Topics\" data-toc-modified-id=\"Finding-Best-Number-of-Topics-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Finding Best Number of Topics</a></span></li><li><span><a href=\"#Sandbox\" data-toc-modified-id=\"Sandbox-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Sandbox</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "`pandas`\n",
    "\n",
    "`seaborn` \n",
    "\n",
    "`spacy`\n",
    "\n",
    "`python -m spacy download en` - english model from spacy\n",
    "\n",
    "`gensim`\n",
    "\n",
    "`pyLDAvis`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting deprecation error that likely is fixed with an update but will surpress for now\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "To analyse the body of the Enron emails and conduct topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "from os.path import relpath\n",
    "\n",
    "# wrangling\n",
    "import pandas as pd\n",
    "\n",
    "# lemmatization\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "# import string\n",
    "\n",
    "# gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "# # plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "    \n",
    "sb.set(style=\"whitegrid\") # to show plots well in darktheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(relpath(\"../data/email_fields.csv\"))[\"Body\"]\n",
    "data.describe()\n",
    "# data = data.tolist()\n",
    "\n",
    "# subset for speed in testing\n",
    "data = data.sample(100000, random_state=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    \"\"\"\n",
    "    Takes a string and breaks it into words.\n",
    "    \n",
    "    Arg:\n",
    "        sentences (str) : The sentence(s) to be broken down\n",
    "        \n",
    "    Returns:\n",
    "        (list) : words as a list\n",
    "    \"\"\"\n",
    "#     return [simple_preprocess(sentence, deacc=True) for sentence in tqdm(sentences)]\n",
    "    \n",
    "    for sentence in tqdm(sentences):\n",
    "        yield(simple_preprocess(sentence, deacc=True)) # deacc removes punctuation\n",
    "\n",
    "def remove_stopwords(texts, stop_words):\n",
    "    \"\"\"\n",
    "    Removes the stop words from a piece of text using a specified list of stop words.\n",
    "    \n",
    "    Args:\n",
    "        text (list) : text to have stop words removed from. Should be split by word and given as a list.\n",
    "        stop_words (set) : stop words for laguage the `text`.\n",
    "        \n",
    "    Returns:\n",
    "        (list) : text list with stop words removed\n",
    "    \"\"\"\n",
    "#     for body in texts:\n",
    "#         yield([word for word in body if word not in stop_words])\n",
    "    return [[word for word in body if word not in stop_words] for body in texts]\n",
    "    \n",
    "def make_bigrams(words, min_count = 5, threshold = 10):\n",
    "    \"\"\"\n",
    "    Takes a list of words and return bigrams.\n",
    "    \n",
    "    Args: taken from `gensim.models.phrases.Phrases` documentation.\n",
    "        words (iter) :  can be simply a list, but for larger corpora, \n",
    "                        consider a generator that streams\n",
    "                        the sentences directly from disk/network, \n",
    "                        See :class:`~gensim.models.word2vec.BrownCorpus`, \n",
    "                        :class:`~gensim.models.word2vec.Text8Corpus` \n",
    "                        or :class:`~gensim.models.word2vec.LineSentence` for such examples.\n",
    "        min_count (float), optional : Ignore all words and bigrams with total \n",
    "                            collected count lower than this value.\n",
    "                            Defaults to 5.\n",
    "        threshold (float), optional : Represent a score threshold for forming the phrases \n",
    "                            (higher means fewer phrases). A phrase of words `a` followed \n",
    "                            by `b` is accepted if the score of the phrase is greater than threshold.  \n",
    "                            Heavily depends on concrete scoring-function, see the `scoring` parameter.\n",
    "    \n",
    "    Returns :\n",
    "        (iter) : bigrams\n",
    "        \n",
    "    \"\"\"\n",
    "    bigrams = Phrases(words)\n",
    "    return [[bigram for bigram in bigrams[body]] for body in tqdm(words)]\n",
    "    \n",
    "def make_trigrams(words):\n",
    "    \"\"\"\n",
    "    Takes a list of words and return bigrams.\n",
    "    \n",
    "    Args: taken from `gensim.models.phrases.Phrases` documentation.\n",
    "        words (iter) :  can be simply a list, but for larger corpora, \n",
    "                        consider a generator that streams\n",
    "                        the sentences directly from disk/network, \n",
    "                        See :class:`~gensim.models.word2vec.BrownCorpus`, \n",
    "                        :class:`~gensim.models.word2vec.Text8Corpus` \n",
    "                        or :class:`~gensim.models.word2vec.LineSentence` for such examples.\n",
    "        min_count (float), optional : Ignore all words and bigrams with total \n",
    "                            collected count lower than this value.\n",
    "                            Defaults to 5.\n",
    "        threshold (float), optional : Represent a score threshold for forming the phrases \n",
    "                            (higher means fewer phrases). A phrase of words `a` followed \n",
    "                            by `b` is accepted if the score of the phrase is greater than threshold.  \n",
    "                            Heavily depends on concrete scoring-function, see the `scoring` parameter.\n",
    "    Returns:\n",
    "        (iter) : trigrams\n",
    "    \"\"\"\n",
    "    return Phrases(make_bigrams(words)[words])\n",
    "    \n",
    "    \n",
    "    \n",
    "def lemmatisation(text, nlp, allowed_postags = [\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    \"\"\"\n",
    "    Lemmatises text.  See: 'https://spacy.io/api/annotation' for more info on `allowed_postags`\n",
    "    \n",
    "    Args:\n",
    "        text (str) : texts to be lemmatised.\n",
    "        nlp : the laguage model of choice.  Defaults to `English` from `spacy`\n",
    "        allowed_postags (list) : list of parts of speech to be lemmatised.\n",
    "       \n",
    "    Returns:\n",
    "        (list)\n",
    "    \"\"\"\n",
    "    text_out = []\n",
    "    for words in tqdm(text):\n",
    "        body = nlp(\" \".join(words))\n",
    "        text_out.append([token.lemma_ for token in body if token.pos_ in allowed_postags])\n",
    "    return text_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenise Email Bodies\n",
    "Break the email bodies into words to prepare for analysing them.  In general, emails which share more words will be about similar topics. \"Rare\" or infrequently used words are likely to indicate important information than words which show up in all email, e.g. \"the\" does not say much about the content of the email, but \"investment\" does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "%pprint # disable pretty print to keep things a bit more compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished constructing word lists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# split email bodies into their component words.\n",
    "data_words = sent_to_words(data)\n",
    "\n",
    "# memory management \n",
    "# del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatisation\n",
    "In order to simplify the data and amplify the signal from words witht the same stem, e.g. is, were, am = be, the data needs to be lemmatised.\n",
    "\n",
    "To do so I will use `Spacy`, which has the benifit of also identify which part of speech each lemma is e.g. noun, verb etc.\n",
    "\n",
    "I take the major parts of speech I believe contribute to topics; nouns, adjectives, verb and adverbs.  There is a case to be made for taking proper nouns so as to include people and this is a factor that may also be worth including. Stop words are also removed using the stop words from `Spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nowhere', 'a', 'through', 'latterly', 'who', 'one', 'go', 'put', 'anyhow', 'after', 'when', 'herself', 'quite', 'whereby', \"'ve\", '‘re', 'everyone', 'get', 'whereas', 'where', 'via', 'against', 'out', 'thru', 'everywhere', 'the', 'still', 'always', 'them', 'five', 'himself', 'indeed', 'several', 'also', 'noone', 'almost', 'whither', 'whom', 'enough', 'thus', 'nor', \"'re\", 'than', 'being', 'it', 'moreover', 'becomes', 'nevertheless', 'except', 'once', 'give', 'will', 'is', 'his', 'their', '’d', 'ten', 'never', 'not', 'under', 'n‘t', 'be', 'least', 'show', 'due', '’ve', 'other', 'amount', 'seems', 'formerly', 'down', 're', 'whereupon', 'nine', 'he', 'n’t', 'bottom', 'but', 'everything', 'further', 'thence', 'more', '’s', 'sixty', 'only', 'are', 'wherein', 'hereafter', '’ll', 'empty', 'should', 'both', 'alone', 'two', 'whose', 'why', 'third', 'again', 'become', 'someone', 'often', 'that', \"'d\", 'of', 'besides', 'has', 'sometime', 'various', 'much', 'may', 'six', 'now', 'whenever', 'without', 'by', 'nothing', 'might', 'anywhere', 'very', 'do', 'her', 'yours', 'really', 'four', 'until', 'had', 'used', \"'m\", 'too', 'us', 'whoever', 'first', 'back', 'all', 'thereupon', 'others', 'something', 'becoming', 'itself', 'none', 'somehow', 'amongst', 'anyway', 'whereafter', 'few', \"n't\", 'full', 'eight', 'even', 'say', 'at', 'could', 'fifty', 'there', '‘d', 'some', 'how', '‘m', 'beside', 'have', 'per', 'elsewhere', 'last', 'myself', 'less', 'wherever', 'another', 'twenty', 'made', 'was', 'whatever', 'an', 'eleven', 'any', 'otherwise', 'whence', 'ours', 'thereby', 'so', 'keep', 'seeming', 'therefore', 'with', \"'s\", 'they', 'anyone', 'using', 'afterwards', 'mine', 'behind', 'latter', 'over', 'name', 'between', 'whole', 'already', 'take', 'which', 'hence', 'towards', 'sometimes', 'across', 'such', 'among', 'my', 'no', 'here', 'along', 'to', 'or', 'see', 'seemed', 'i', 'ourselves', 'twelve', 'top', 'within', 'just', 'else', 'perhaps', 'does', 'him', 'every', 'while', 'doing', 'side', 'meanwhile', 'most', 'anything', 'on', 'forty', 'many', 'each', 'if', 'for', 'were', 'three', 'herein', 'hereby', 'rather', 'our', 'serious', 'then', 'and', 'hereupon', 'done', 'we', 'part', 'above', 'these', 'cannot', 'neither', 'into', 'own', 'what', 'ca', 'would', 'yourselves', 'beyond', 'can', 'its', 'same', 'make', 'this', 'nobody', 'although', 'me', 'please', 'seem', 'became', 'though', 'as', 'below', 'off', '’re', 'upon', 'before', 'call', 'from', 'she', 'throughout', 'about', 'unless', 'next', '‘ll', 'did', 'because', 'however', 'namely', 'you', 'around', 'mostly', 'well', 'been', '‘ve', 'themselves', 'front', 'yourself', 'beforehand', 'yet', 'regarding', 'toward', 'in', 'either', 'ever', 'together', 'onto', 'somewhere', 'those', 'up', 'former', 'your', 'fifteen', 'move', '‘s', 'therein', 'thereafter', 'hundred', 'whether', 'since', 'must', '’m', 'hers', 'am', 'during', \"'ll\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = STOP_WORDS\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nowhere', 'a', 'through', 'latterly', 'who', 'one', 'go', 'put', 'anyhow', 'after', 'when', 'herself', 'quite', 'whereby', \"'ve\", '‘re', 'everyone', 'get', 'whereas', 'where', 'via', 'against', 'out', 'thru', 'everywhere', 'the', 'still', 'always', 'them', 'five', 'himself', 'indeed', 'several', 'also', 'noone', 'almost', 'whither', 'whom', 'enough', 'thus', 'nor', \"'re\", 'than', 'being', 'it', 'moreover', 'becomes', 'nevertheless', 'except', 'once', 'give', 'will', 'is', 'his', 'their', '’d', 'ten', 'never', 'not', 'under', 'n‘t', 'be', 'least', 'show', 'due', '’ve', 'other', 'amount', 'seems', 'formerly', 'down', 're', 'whereupon', 'nine', 'he', 'n’t', 'bottom', 'but', 'everything', 'further', 'thence', 'more', '’s', 'sixty', 'only', 'are', 'wherein', 'hereafter', '’ll', 'empty', 'should', 'both', 'alone', 'two', 'whose', 'why', 'third', 'again', 'become', 'someone', 'often', 'that', \"'d\", 'of', 'besides', 'has', 'sometime', 'various', 'much', 'may', 'six', 'now', 'whenever', 'without', 'by', 'nothing', 'might', 'anywhere', 'very', 'do', 'her', 'yours', 'really', 'four', 'until', 'had', 'used', \"'m\", 'too', 'us', 'whoever', 'first', 'back', 'all', 'thereupon', 'others', 'something', 'becoming', 'itself', 'none', 'somehow', 'amongst', 'anyway', 'whereafter', 'few', \"n't\", 'full', 'eight', 'even', 'say', 'at', 'could', 'fifty', 'there', '‘d', 'some', 'how', '‘m', 'beside', 'have', 'per', 'elsewhere', 'last', 'myself', 'less', 'wherever', 'another', 'twenty', 'made', 'was', 'whatever', 'an', 'eleven', 'any', 'forward', 'otherwise', 'whence', 'ours', 'thereby', 'so', 'keep', 'seeming', 'therefore', 'with', \"'s\", 'they', 'anyone', 'using', 'afterwards', 'mine', 'behind', 'latter', 'over', 'name', 'between', 'etc', 'whole', 'already', 'take', 'which', 'hence', 'towards', 'sometimes', 'across', 'such', 'among', 'my', 'no', 'here', 'along', 'to', 'or', 'see', 'seemed', 'i', 'ourselves', 'twelve', 'top', 'within', 'just', 'else', 'perhaps', 'does', 'him', 'every', 'while', 'doing', 'side', 'meanwhile', 'most', 'anything', 'on', 'forty', 'many', 'each', 'if', 'for', 'were', 'edu', 'three', 'herein', 'hereby', 'rather', 'our', 'serious', 'then', 'and', 'hereupon', 'done', 'we', 'part', 'above', 'these', 'cannot', 'neither', 'into', 'own', 'what', 'ca', 'would', 'yourselves', 'beyond', 'can', 'its', 'same', 'make', 'this', 'nobody', 'although', 'me', 'please', 'com', 'subject', 'seem', 'became', 'though', 'as', 'below', 'off', '’re', 'upon', 'before', 'call', 'from', 'she', 'throughout', 'about', 'unless', 'next', '‘ll', 'did', 'because', 'however', 'namely', 'you', 'around', 'mostly', 'well', 'been', '‘ve', 'themselves', 'front', 'yourself', 'beforehand', 'yet', 'regarding', 'toward', 'in', 'either', 'ever', 'together', 'onto', 'somewhere', 'those', 'up', 'former', 'your', 'fifteen', 'move', '‘s', 'therein', 'thereafter', 'hundred', 'whether', 'since', 'cc', 'must', '’m', 'hers', 'am', 'during', \"'ll\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add use case specific words to exclude \n",
    "words_to_add = {\"etc\", \"subject\", \"com\", \"forward\", \"cc\", \"from\", \"edu\"}\n",
    "stop_words.update(words_to_add)\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|██████████| 100000/100000 [01:20<00:00, 1242.43it/s]\n"
     ]
    }
   ],
   "source": [
    "no_stop_words = remove_stopwords(texts = data_words, stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(no_stop_words, open(\"../data/no_stop_words.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['second', 'thanks', 'lot', 'dfmartha', 'benner', 'pmto', 'don', 'nelson', 'et', 'enron', 'enron', 'norm', 'ruiz', 'et', 'enron', 'enroncc', 'rod', 'williams', 'et', 'enron', 'enron', 'bcc', 'drew', 'fossum', 'et', 'enron', 'satellite', 'phonewant', 'thank', 'help', 'obtaining', 'satellite', 'phone', 'usage', 'short', 'notice', 'able', 'come', 'hesitation', 'parts', 'nice', 'good', 'people', 'work', 'helpful', 'professional', 'situation', 'novice', 'phone', 'thing', 'helpful', 'step', 'way', 'thank', 'martha', 'benner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory management\n",
    "del data\n",
    "del data_words\n",
    "no_stop_words[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams\n",
    "Bigrams are two words which are often used together and as such can almost be considered one word for the analysis, e.g. chinese food.  This can be extended to n-grams but will not be for this analysis.\n",
    "\n",
    "Using defaults of `threshold=10` for the time being but may adjust later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|██████████| 100000/100000 [00:55<00:00, 1799.73it/s]\n"
     ]
    }
   ],
   "source": [
    "words_bigrams = make_bigrams(no_stop_words)\n",
    "# mem mamnagement\n",
    "del no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(words_bigrams, open(\"../data/words_bigrams.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donal/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      " 60%|██████    | 60383/100000 [12:06<08:19, 79.31it/s] "
     ]
    }
   ],
   "source": [
    "words_lemmatised = lemmatisation(words_bigrams, nlp = nlp, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "# mem mamnagement\n",
    "del words_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words_lemmatised, open(\"../data/words_lemmatised.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_lemmatised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lemmatised = pickle.load(open(\"../data/words_lemmatised.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the Corpus and LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corpus dictionary\n",
    "dictionary = corpora.Dictionary(words_lemmatised)\n",
    "\n",
    "# Corpus is just the `words_lemmatised` var that has been made above\n",
    "# Term document frequency\n",
    "corpus = [dictionary.doc2bow(text) for text in words_lemmatised]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=20,\n",
    "                     random_state=100,\n",
    "                     update_every=1,\n",
    "                     chunksize=100,\n",
    "                     passes=10,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lda_model, open(\"../data/lda_test.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity and Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a measure of how good the model is. lower the better.)\n",
    "print('Perplexity: %f' % lda_model.log_perplexity(corpus))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model = lda_model, texts= words_lemmatised, \n",
    "                                     dictionary = dictionary, coherence = 'c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: %f' % coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook(sort=True)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Number of Topics\n",
    "There is a lot of grouping in smaller topics in the graph so will run tests to find the best number of topics using coherence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coherence(corpus, dictionary, texts, limit, start = 2, step = 2):\n",
    "    \"\"\"\n",
    "    Compute coherence of LDA models for increasing number of topics.\n",
    "    \n",
    "    Args:\n",
    "        corpus () :\n",
    "        dictionary () : \n",
    "        texts () : \n",
    "        limit (int) : Maximum number of topics to simulate to.\n",
    "        start (int) : How many topics to start with. \n",
    "                        Defaults to 2.\n",
    "        step (int) : How many topics to increase by for each iteration. \n",
    "                        Defaults to 2.\n",
    "                        \n",
    "    Returns:\n",
    "        (list) : [model_list, coherence_list] -> models that produce their corresponding coherence values as a list.        \n",
    "    \"\"\"\n",
    "    model_list = []\n",
    "    coherence_list = []\n",
    "    \n",
    "    for topics in tqdm(range(start, limit, step)):\n",
    "        model = LdaModel(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=topics,\n",
    "                         random_state=100,\n",
    "                         update_every=1,\n",
    "                         chunksize=100,\n",
    "                         passes=10,\n",
    "                         alpha='auto',\n",
    "                         per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        \n",
    "        coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherence_model.get_coherence()\n",
    "        coherence_list.append(coherence_score)\n",
    "        \n",
    "    return [model_list, coherence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 20\n",
    "start = 2\n",
    "step = 2\n",
    "\n",
    "\n",
    "model_list, coherence_list = calc_coherence(corpus = corpus, dictionary = dictionary, texts = words_lemmatised,\n",
    "                                           limit = limit, start = start, step = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(start, limit, step)\n",
    "fig = plt.figure()\n",
    "ax = plt.plot(x, coherence_list)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_list, open(\"../data/model_list.p\", \"wb\"))\n",
    "pickle.dump(coherence_list, open(\"../data/coherence_list.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can judge the point of diminishing returns / accuracy loss for number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of max coherence\n",
    "max_index = [i for i in range(len(coherence_list)) if max(coherence_list) == coherence_list[i]][0]\n",
    "optimum_model = model_list[max_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook(sort=True)\n",
    "vis = pyLDAvis.gensim.prepare(optimum_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox\n",
    "Code testing ground. Ignore all below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "100px",
    "left": "47px",
    "top": "102px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
